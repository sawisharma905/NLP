{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-20ececcea799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpora'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[1;31m# Identify the package (i.e. the .zip file) to download.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[0mresource_zipname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresource_zipname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.zip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mresource_zipname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresource_zipname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gutenberg', 'gutenberg.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:500]:\n",
    "    print(word,sep=\" \",end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-41-e135901e3aa7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-41-e135901e3aa7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    cnn=\"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The fully-connectedness of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns.\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "cnn=\"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The fully-connectedness of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'a',\n",
       " 'convolutional',\n",
       " 'neural',\n",
       " 'network',\n",
       " '(',\n",
       " 'CNN',\n",
       " ',',\n",
       " 'or',\n",
       " 'ConvNet',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'class',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'networks',\n",
       " ',',\n",
       " 'most',\n",
       " 'commonly',\n",
       " 'applied',\n",
       " 'to',\n",
       " 'analyzing',\n",
       " 'visual',\n",
       " 'imagery',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'also',\n",
       " 'known',\n",
       " 'as',\n",
       " 'shift',\n",
       " 'invariant',\n",
       " 'or',\n",
       " 'space',\n",
       " 'invariant',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'networks',\n",
       " '(',\n",
       " 'SIANN',\n",
       " ')',\n",
       " ',',\n",
       " 'based',\n",
       " 'on',\n",
       " 'their',\n",
       " 'shared-weights',\n",
       " 'architecture',\n",
       " 'and',\n",
       " 'translation',\n",
       " 'invariance',\n",
       " 'characteristics.They',\n",
       " 'have',\n",
       " 'applications',\n",
       " 'in',\n",
       " 'image',\n",
       " 'and',\n",
       " 'video',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'recommender',\n",
       " 'systems',\n",
       " ',',\n",
       " 'image',\n",
       " 'classification',\n",
       " ',',\n",
       " 'medical',\n",
       " 'image',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " ',',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'time',\n",
       " 'series.CNNs',\n",
       " 'are',\n",
       " 'regularized',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'multilayer',\n",
       " 'perceptrons',\n",
       " '.',\n",
       " 'Multilayer',\n",
       " 'perceptrons',\n",
       " 'usually',\n",
       " 'mean',\n",
       " 'fully',\n",
       " 'connected',\n",
       " 'networks',\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " ',',\n",
       " 'each',\n",
       " 'neuron',\n",
       " 'in',\n",
       " 'one',\n",
       " 'layer',\n",
       " 'is',\n",
       " 'connected',\n",
       " 'to',\n",
       " 'all',\n",
       " 'neurons',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'layer',\n",
       " '.',\n",
       " 'The',\n",
       " 'fully-connectedness',\n",
       " 'of',\n",
       " 'these',\n",
       " 'networks',\n",
       " 'makes',\n",
       " 'them',\n",
       " 'prone',\n",
       " 'to',\n",
       " 'overfitting',\n",
       " 'data',\n",
       " '.',\n",
       " 'Typical',\n",
       " 'ways',\n",
       " 'of',\n",
       " 'regularization',\n",
       " 'include',\n",
       " 'adding',\n",
       " 'some',\n",
       " 'form',\n",
       " 'of',\n",
       " 'magnitude',\n",
       " 'measurement',\n",
       " 'of',\n",
       " 'weights',\n",
       " 'to',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'function',\n",
       " '.',\n",
       " 'CNNs',\n",
       " 'take',\n",
       " 'a',\n",
       " 'different',\n",
       " 'approach',\n",
       " 'towards',\n",
       " 'regularization',\n",
       " ':',\n",
       " 'they',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hierarchical',\n",
       " 'pattern',\n",
       " 'in',\n",
       " 'data',\n",
       " 'and',\n",
       " 'assemble',\n",
       " 'more',\n",
       " 'complex',\n",
       " 'patterns',\n",
       " 'using',\n",
       " 'smaller',\n",
       " 'and',\n",
       " 'simpler',\n",
       " 'patterns',\n",
       " '.',\n",
       " 'Therefore',\n",
       " ',',\n",
       " 'on',\n",
       " 'the',\n",
       " 'scale',\n",
       " 'of',\n",
       " 'connectedness',\n",
       " 'and',\n",
       " 'complexity',\n",
       " ',',\n",
       " 'CNNs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'lower',\n",
       " 'extreme',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_tokens=word_tokenize(cnn)\n",
    "cnn_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 13, 'of': 8, '.': 7, 'and': 6, 'the': 6, 'in': 5, 'networks': 4, 'to': 4, 'a': 3, 'neural': 3, ...})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist=FreqDist()\n",
    "#to find the word cound of all the words in the data\n",
    "for word in cnn_tokens:\n",
    "    fdist[word.lower()]+=1   #here we simultaneously converting the words to the lower case\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 13),\n",
       " ('of', 8),\n",
       " ('.', 7),\n",
       " ('and', 6),\n",
       " ('the', 6),\n",
       " ('in', 5),\n",
       " ('networks', 4),\n",
       " ('to', 4),\n",
       " ('a', 3),\n",
       " ('neural', 3)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10=fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to show how many paragraphs are there and how many paragraphs are separated by a new line\n",
    "from nltk.tokenize import blankline_tokenize\n",
    "cnn_blank=blankline_tokenize(cnn)\n",
    "len(cnn_blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram : tokens of two consecutive written words\n",
    "#### Trigram : tokens of three consecutive written words\n",
    "#### Ngram : tokens of any number of consecutive written words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams , trigrams , ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'deep'),\n",
       " ('deep', 'learning'),\n",
       " ('learning', ','),\n",
       " (',', 'a'),\n",
       " ('a', 'convolutional'),\n",
       " ('convolutional', 'neural'),\n",
       " ('neural', 'network'),\n",
       " ('network', '('),\n",
       " ('(', 'CNN'),\n",
       " ('CNN', ','),\n",
       " (',', 'or'),\n",
       " ('or', 'ConvNet'),\n",
       " ('ConvNet', ')'),\n",
       " (')', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'class'),\n",
       " ('class', 'of'),\n",
       " ('of', 'deep'),\n",
       " ('deep', 'neural'),\n",
       " ('neural', 'networks'),\n",
       " ('networks', ','),\n",
       " (',', 'most'),\n",
       " ('most', 'commonly'),\n",
       " ('commonly', 'applied'),\n",
       " ('applied', 'to'),\n",
       " ('to', 'analyzing'),\n",
       " ('analyzing', 'visual'),\n",
       " ('visual', 'imagery'),\n",
       " ('imagery', '.'),\n",
       " ('.', 'They'),\n",
       " ('They', 'are'),\n",
       " ('are', 'also'),\n",
       " ('also', 'known'),\n",
       " ('known', 'as'),\n",
       " ('as', 'shift'),\n",
       " ('shift', 'invariant'),\n",
       " ('invariant', 'or'),\n",
       " ('or', 'space'),\n",
       " ('space', 'invariant'),\n",
       " ('invariant', 'artificial'),\n",
       " ('artificial', 'neural'),\n",
       " ('neural', 'networks'),\n",
       " ('networks', '('),\n",
       " ('(', 'SIANN'),\n",
       " ('SIANN', ')'),\n",
       " (')', ','),\n",
       " (',', 'based'),\n",
       " ('based', 'on'),\n",
       " ('on', 'their'),\n",
       " ('their', 'shared-weights'),\n",
       " ('shared-weights', 'architecture'),\n",
       " ('architecture', 'and'),\n",
       " ('and', 'translation'),\n",
       " ('translation', 'invariance'),\n",
       " ('invariance', 'characteristics.They'),\n",
       " ('characteristics.They', 'have'),\n",
       " ('have', 'applications'),\n",
       " ('applications', 'in'),\n",
       " ('in', 'image'),\n",
       " ('image', 'and'),\n",
       " ('and', 'video'),\n",
       " ('video', 'recognition'),\n",
       " ('recognition', ','),\n",
       " (',', 'recommender'),\n",
       " ('recommender', 'systems'),\n",
       " ('systems', ','),\n",
       " (',', 'image'),\n",
       " ('image', 'classification'),\n",
       " ('classification', ','),\n",
       " (',', 'medical'),\n",
       " ('medical', 'image'),\n",
       " ('image', 'analysis'),\n",
       " ('analysis', ','),\n",
       " (',', 'natural'),\n",
       " ('natural', 'language'),\n",
       " ('language', 'processing'),\n",
       " ('processing', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'financial'),\n",
       " ('financial', 'time'),\n",
       " ('time', 'series.CNNs'),\n",
       " ('series.CNNs', 'are'),\n",
       " ('are', 'regularized'),\n",
       " ('regularized', 'versions'),\n",
       " ('versions', 'of'),\n",
       " ('of', 'multilayer'),\n",
       " ('multilayer', 'perceptrons'),\n",
       " ('perceptrons', '.'),\n",
       " ('.', 'Multilayer'),\n",
       " ('Multilayer', 'perceptrons'),\n",
       " ('perceptrons', 'usually'),\n",
       " ('usually', 'mean'),\n",
       " ('mean', 'fully'),\n",
       " ('fully', 'connected'),\n",
       " ('connected', 'networks'),\n",
       " ('networks', ','),\n",
       " (',', 'that'),\n",
       " ('that', 'is'),\n",
       " ('is', ','),\n",
       " (',', 'each'),\n",
       " ('each', 'neuron'),\n",
       " ('neuron', 'in'),\n",
       " ('in', 'one'),\n",
       " ('one', 'layer'),\n",
       " ('layer', 'is'),\n",
       " ('is', 'connected'),\n",
       " ('connected', 'to'),\n",
       " ('to', 'all'),\n",
       " ('all', 'neurons'),\n",
       " ('neurons', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'next'),\n",
       " ('next', 'layer'),\n",
       " ('layer', '.'),\n",
       " ('.', 'The'),\n",
       " ('The', 'fully-connectedness'),\n",
       " ('fully-connectedness', 'of'),\n",
       " ('of', 'these'),\n",
       " ('these', 'networks'),\n",
       " ('networks', 'makes'),\n",
       " ('makes', 'them'),\n",
       " ('them', 'prone'),\n",
       " ('prone', 'to'),\n",
       " ('to', 'overfitting'),\n",
       " ('overfitting', 'data'),\n",
       " ('data', '.'),\n",
       " ('.', 'Typical'),\n",
       " ('Typical', 'ways'),\n",
       " ('ways', 'of'),\n",
       " ('of', 'regularization'),\n",
       " ('regularization', 'include'),\n",
       " ('include', 'adding'),\n",
       " ('adding', 'some'),\n",
       " ('some', 'form'),\n",
       " ('form', 'of'),\n",
       " ('of', 'magnitude'),\n",
       " ('magnitude', 'measurement'),\n",
       " ('measurement', 'of'),\n",
       " ('of', 'weights'),\n",
       " ('weights', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'loss'),\n",
       " ('loss', 'function'),\n",
       " ('function', '.'),\n",
       " ('.', 'CNNs'),\n",
       " ('CNNs', 'take'),\n",
       " ('take', 'a'),\n",
       " ('a', 'different'),\n",
       " ('different', 'approach'),\n",
       " ('approach', 'towards'),\n",
       " ('towards', 'regularization'),\n",
       " ('regularization', ':'),\n",
       " (':', 'they'),\n",
       " ('they', 'take'),\n",
       " ('take', 'advantage'),\n",
       " ('advantage', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'hierarchical'),\n",
       " ('hierarchical', 'pattern'),\n",
       " ('pattern', 'in'),\n",
       " ('in', 'data'),\n",
       " ('data', 'and'),\n",
       " ('and', 'assemble'),\n",
       " ('assemble', 'more'),\n",
       " ('more', 'complex'),\n",
       " ('complex', 'patterns'),\n",
       " ('patterns', 'using'),\n",
       " ('using', 'smaller'),\n",
       " ('smaller', 'and'),\n",
       " ('and', 'simpler'),\n",
       " ('simpler', 'patterns'),\n",
       " ('patterns', '.'),\n",
       " ('.', 'Therefore'),\n",
       " ('Therefore', ','),\n",
       " (',', 'on'),\n",
       " ('on', 'the'),\n",
       " ('the', 'scale'),\n",
       " ('scale', 'of'),\n",
       " ('of', 'connectedness'),\n",
       " ('connectedness', 'and'),\n",
       " ('and', 'complexity'),\n",
       " ('complexity', ','),\n",
       " (',', 'CNNs'),\n",
       " ('CNNs', 'are'),\n",
       " ('are', 'on'),\n",
       " ('on', 'the'),\n",
       " ('the', 'lower'),\n",
       " ('lower', 'extreme'),\n",
       " ('extreme', '.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_bigrams=list(nltk.bigrams(cnn_tokens))\n",
    "cnn_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'deep', 'learning'),\n",
       " ('deep', 'learning', ','),\n",
       " ('learning', ',', 'a'),\n",
       " (',', 'a', 'convolutional'),\n",
       " ('a', 'convolutional', 'neural'),\n",
       " ('convolutional', 'neural', 'network'),\n",
       " ('neural', 'network', '('),\n",
       " ('network', '(', 'CNN'),\n",
       " ('(', 'CNN', ','),\n",
       " ('CNN', ',', 'or'),\n",
       " (',', 'or', 'ConvNet'),\n",
       " ('or', 'ConvNet', ')'),\n",
       " ('ConvNet', ')', 'is'),\n",
       " (')', 'is', 'a'),\n",
       " ('is', 'a', 'class'),\n",
       " ('a', 'class', 'of'),\n",
       " ('class', 'of', 'deep'),\n",
       " ('of', 'deep', 'neural'),\n",
       " ('deep', 'neural', 'networks'),\n",
       " ('neural', 'networks', ','),\n",
       " ('networks', ',', 'most'),\n",
       " (',', 'most', 'commonly'),\n",
       " ('most', 'commonly', 'applied'),\n",
       " ('commonly', 'applied', 'to'),\n",
       " ('applied', 'to', 'analyzing'),\n",
       " ('to', 'analyzing', 'visual'),\n",
       " ('analyzing', 'visual', 'imagery'),\n",
       " ('visual', 'imagery', '.'),\n",
       " ('imagery', '.', 'They'),\n",
       " ('.', 'They', 'are'),\n",
       " ('They', 'are', 'also'),\n",
       " ('are', 'also', 'known'),\n",
       " ('also', 'known', 'as'),\n",
       " ('known', 'as', 'shift'),\n",
       " ('as', 'shift', 'invariant'),\n",
       " ('shift', 'invariant', 'or'),\n",
       " ('invariant', 'or', 'space'),\n",
       " ('or', 'space', 'invariant'),\n",
       " ('space', 'invariant', 'artificial'),\n",
       " ('invariant', 'artificial', 'neural'),\n",
       " ('artificial', 'neural', 'networks'),\n",
       " ('neural', 'networks', '('),\n",
       " ('networks', '(', 'SIANN'),\n",
       " ('(', 'SIANN', ')'),\n",
       " ('SIANN', ')', ','),\n",
       " (')', ',', 'based'),\n",
       " (',', 'based', 'on'),\n",
       " ('based', 'on', 'their'),\n",
       " ('on', 'their', 'shared-weights'),\n",
       " ('their', 'shared-weights', 'architecture'),\n",
       " ('shared-weights', 'architecture', 'and'),\n",
       " ('architecture', 'and', 'translation'),\n",
       " ('and', 'translation', 'invariance'),\n",
       " ('translation', 'invariance', 'characteristics.They'),\n",
       " ('invariance', 'characteristics.They', 'have'),\n",
       " ('characteristics.They', 'have', 'applications'),\n",
       " ('have', 'applications', 'in'),\n",
       " ('applications', 'in', 'image'),\n",
       " ('in', 'image', 'and'),\n",
       " ('image', 'and', 'video'),\n",
       " ('and', 'video', 'recognition'),\n",
       " ('video', 'recognition', ','),\n",
       " ('recognition', ',', 'recommender'),\n",
       " (',', 'recommender', 'systems'),\n",
       " ('recommender', 'systems', ','),\n",
       " ('systems', ',', 'image'),\n",
       " (',', 'image', 'classification'),\n",
       " ('image', 'classification', ','),\n",
       " ('classification', ',', 'medical'),\n",
       " (',', 'medical', 'image'),\n",
       " ('medical', 'image', 'analysis'),\n",
       " ('image', 'analysis', ','),\n",
       " ('analysis', ',', 'natural'),\n",
       " (',', 'natural', 'language'),\n",
       " ('natural', 'language', 'processing'),\n",
       " ('language', 'processing', ','),\n",
       " ('processing', ',', 'and'),\n",
       " (',', 'and', 'financial'),\n",
       " ('and', 'financial', 'time'),\n",
       " ('financial', 'time', 'series.CNNs'),\n",
       " ('time', 'series.CNNs', 'are'),\n",
       " ('series.CNNs', 'are', 'regularized'),\n",
       " ('are', 'regularized', 'versions'),\n",
       " ('regularized', 'versions', 'of'),\n",
       " ('versions', 'of', 'multilayer'),\n",
       " ('of', 'multilayer', 'perceptrons'),\n",
       " ('multilayer', 'perceptrons', '.'),\n",
       " ('perceptrons', '.', 'Multilayer'),\n",
       " ('.', 'Multilayer', 'perceptrons'),\n",
       " ('Multilayer', 'perceptrons', 'usually'),\n",
       " ('perceptrons', 'usually', 'mean'),\n",
       " ('usually', 'mean', 'fully'),\n",
       " ('mean', 'fully', 'connected'),\n",
       " ('fully', 'connected', 'networks'),\n",
       " ('connected', 'networks', ','),\n",
       " ('networks', ',', 'that'),\n",
       " (',', 'that', 'is'),\n",
       " ('that', 'is', ','),\n",
       " ('is', ',', 'each'),\n",
       " (',', 'each', 'neuron'),\n",
       " ('each', 'neuron', 'in'),\n",
       " ('neuron', 'in', 'one'),\n",
       " ('in', 'one', 'layer'),\n",
       " ('one', 'layer', 'is'),\n",
       " ('layer', 'is', 'connected'),\n",
       " ('is', 'connected', 'to'),\n",
       " ('connected', 'to', 'all'),\n",
       " ('to', 'all', 'neurons'),\n",
       " ('all', 'neurons', 'in'),\n",
       " ('neurons', 'in', 'the'),\n",
       " ('in', 'the', 'next'),\n",
       " ('the', 'next', 'layer'),\n",
       " ('next', 'layer', '.'),\n",
       " ('layer', '.', 'The'),\n",
       " ('.', 'The', 'fully-connectedness'),\n",
       " ('The', 'fully-connectedness', 'of'),\n",
       " ('fully-connectedness', 'of', 'these'),\n",
       " ('of', 'these', 'networks'),\n",
       " ('these', 'networks', 'makes'),\n",
       " ('networks', 'makes', 'them'),\n",
       " ('makes', 'them', 'prone'),\n",
       " ('them', 'prone', 'to'),\n",
       " ('prone', 'to', 'overfitting'),\n",
       " ('to', 'overfitting', 'data'),\n",
       " ('overfitting', 'data', '.'),\n",
       " ('data', '.', 'Typical'),\n",
       " ('.', 'Typical', 'ways'),\n",
       " ('Typical', 'ways', 'of'),\n",
       " ('ways', 'of', 'regularization'),\n",
       " ('of', 'regularization', 'include'),\n",
       " ('regularization', 'include', 'adding'),\n",
       " ('include', 'adding', 'some'),\n",
       " ('adding', 'some', 'form'),\n",
       " ('some', 'form', 'of'),\n",
       " ('form', 'of', 'magnitude'),\n",
       " ('of', 'magnitude', 'measurement'),\n",
       " ('magnitude', 'measurement', 'of'),\n",
       " ('measurement', 'of', 'weights'),\n",
       " ('of', 'weights', 'to'),\n",
       " ('weights', 'to', 'the'),\n",
       " ('to', 'the', 'loss'),\n",
       " ('the', 'loss', 'function'),\n",
       " ('loss', 'function', '.'),\n",
       " ('function', '.', 'CNNs'),\n",
       " ('.', 'CNNs', 'take'),\n",
       " ('CNNs', 'take', 'a'),\n",
       " ('take', 'a', 'different'),\n",
       " ('a', 'different', 'approach'),\n",
       " ('different', 'approach', 'towards'),\n",
       " ('approach', 'towards', 'regularization'),\n",
       " ('towards', 'regularization', ':'),\n",
       " ('regularization', ':', 'they'),\n",
       " (':', 'they', 'take'),\n",
       " ('they', 'take', 'advantage'),\n",
       " ('take', 'advantage', 'of'),\n",
       " ('advantage', 'of', 'the'),\n",
       " ('of', 'the', 'hierarchical'),\n",
       " ('the', 'hierarchical', 'pattern'),\n",
       " ('hierarchical', 'pattern', 'in'),\n",
       " ('pattern', 'in', 'data'),\n",
       " ('in', 'data', 'and'),\n",
       " ('data', 'and', 'assemble'),\n",
       " ('and', 'assemble', 'more'),\n",
       " ('assemble', 'more', 'complex'),\n",
       " ('more', 'complex', 'patterns'),\n",
       " ('complex', 'patterns', 'using'),\n",
       " ('patterns', 'using', 'smaller'),\n",
       " ('using', 'smaller', 'and'),\n",
       " ('smaller', 'and', 'simpler'),\n",
       " ('and', 'simpler', 'patterns'),\n",
       " ('simpler', 'patterns', '.'),\n",
       " ('patterns', '.', 'Therefore'),\n",
       " ('.', 'Therefore', ','),\n",
       " ('Therefore', ',', 'on'),\n",
       " (',', 'on', 'the'),\n",
       " ('on', 'the', 'scale'),\n",
       " ('the', 'scale', 'of'),\n",
       " ('scale', 'of', 'connectedness'),\n",
       " ('of', 'connectedness', 'and'),\n",
       " ('connectedness', 'and', 'complexity'),\n",
       " ('and', 'complexity', ','),\n",
       " ('complexity', ',', 'CNNs'),\n",
       " (',', 'CNNs', 'are'),\n",
       " ('CNNs', 'are', 'on'),\n",
       " ('are', 'on', 'the'),\n",
       " ('on', 'the', 'lower'),\n",
       " ('the', 'lower', 'extreme'),\n",
       " ('lower', 'extreme', '.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_trigrams=list(nltk.trigrams(cnn_tokens))\n",
    "cnn_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'deep', 'learning', ',', 'a'),\n",
       " ('deep', 'learning', ',', 'a', 'convolutional'),\n",
       " ('learning', ',', 'a', 'convolutional', 'neural'),\n",
       " (',', 'a', 'convolutional', 'neural', 'network'),\n",
       " ('a', 'convolutional', 'neural', 'network', '('),\n",
       " ('convolutional', 'neural', 'network', '(', 'CNN'),\n",
       " ('neural', 'network', '(', 'CNN', ','),\n",
       " ('network', '(', 'CNN', ',', 'or'),\n",
       " ('(', 'CNN', ',', 'or', 'ConvNet'),\n",
       " ('CNN', ',', 'or', 'ConvNet', ')'),\n",
       " (',', 'or', 'ConvNet', ')', 'is'),\n",
       " ('or', 'ConvNet', ')', 'is', 'a'),\n",
       " ('ConvNet', ')', 'is', 'a', 'class'),\n",
       " (')', 'is', 'a', 'class', 'of'),\n",
       " ('is', 'a', 'class', 'of', 'deep'),\n",
       " ('a', 'class', 'of', 'deep', 'neural'),\n",
       " ('class', 'of', 'deep', 'neural', 'networks'),\n",
       " ('of', 'deep', 'neural', 'networks', ','),\n",
       " ('deep', 'neural', 'networks', ',', 'most'),\n",
       " ('neural', 'networks', ',', 'most', 'commonly'),\n",
       " ('networks', ',', 'most', 'commonly', 'applied'),\n",
       " (',', 'most', 'commonly', 'applied', 'to'),\n",
       " ('most', 'commonly', 'applied', 'to', 'analyzing'),\n",
       " ('commonly', 'applied', 'to', 'analyzing', 'visual'),\n",
       " ('applied', 'to', 'analyzing', 'visual', 'imagery'),\n",
       " ('to', 'analyzing', 'visual', 'imagery', '.'),\n",
       " ('analyzing', 'visual', 'imagery', '.', 'They'),\n",
       " ('visual', 'imagery', '.', 'They', 'are'),\n",
       " ('imagery', '.', 'They', 'are', 'also'),\n",
       " ('.', 'They', 'are', 'also', 'known'),\n",
       " ('They', 'are', 'also', 'known', 'as'),\n",
       " ('are', 'also', 'known', 'as', 'shift'),\n",
       " ('also', 'known', 'as', 'shift', 'invariant'),\n",
       " ('known', 'as', 'shift', 'invariant', 'or'),\n",
       " ('as', 'shift', 'invariant', 'or', 'space'),\n",
       " ('shift', 'invariant', 'or', 'space', 'invariant'),\n",
       " ('invariant', 'or', 'space', 'invariant', 'artificial'),\n",
       " ('or', 'space', 'invariant', 'artificial', 'neural'),\n",
       " ('space', 'invariant', 'artificial', 'neural', 'networks'),\n",
       " ('invariant', 'artificial', 'neural', 'networks', '('),\n",
       " ('artificial', 'neural', 'networks', '(', 'SIANN'),\n",
       " ('neural', 'networks', '(', 'SIANN', ')'),\n",
       " ('networks', '(', 'SIANN', ')', ','),\n",
       " ('(', 'SIANN', ')', ',', 'based'),\n",
       " ('SIANN', ')', ',', 'based', 'on'),\n",
       " (')', ',', 'based', 'on', 'their'),\n",
       " (',', 'based', 'on', 'their', 'shared-weights'),\n",
       " ('based', 'on', 'their', 'shared-weights', 'architecture'),\n",
       " ('on', 'their', 'shared-weights', 'architecture', 'and'),\n",
       " ('their', 'shared-weights', 'architecture', 'and', 'translation'),\n",
       " ('shared-weights', 'architecture', 'and', 'translation', 'invariance'),\n",
       " ('architecture', 'and', 'translation', 'invariance', 'characteristics.They'),\n",
       " ('and', 'translation', 'invariance', 'characteristics.They', 'have'),\n",
       " ('translation', 'invariance', 'characteristics.They', 'have', 'applications'),\n",
       " ('invariance', 'characteristics.They', 'have', 'applications', 'in'),\n",
       " ('characteristics.They', 'have', 'applications', 'in', 'image'),\n",
       " ('have', 'applications', 'in', 'image', 'and'),\n",
       " ('applications', 'in', 'image', 'and', 'video'),\n",
       " ('in', 'image', 'and', 'video', 'recognition'),\n",
       " ('image', 'and', 'video', 'recognition', ','),\n",
       " ('and', 'video', 'recognition', ',', 'recommender'),\n",
       " ('video', 'recognition', ',', 'recommender', 'systems'),\n",
       " ('recognition', ',', 'recommender', 'systems', ','),\n",
       " (',', 'recommender', 'systems', ',', 'image'),\n",
       " ('recommender', 'systems', ',', 'image', 'classification'),\n",
       " ('systems', ',', 'image', 'classification', ','),\n",
       " (',', 'image', 'classification', ',', 'medical'),\n",
       " ('image', 'classification', ',', 'medical', 'image'),\n",
       " ('classification', ',', 'medical', 'image', 'analysis'),\n",
       " (',', 'medical', 'image', 'analysis', ','),\n",
       " ('medical', 'image', 'analysis', ',', 'natural'),\n",
       " ('image', 'analysis', ',', 'natural', 'language'),\n",
       " ('analysis', ',', 'natural', 'language', 'processing'),\n",
       " (',', 'natural', 'language', 'processing', ','),\n",
       " ('natural', 'language', 'processing', ',', 'and'),\n",
       " ('language', 'processing', ',', 'and', 'financial'),\n",
       " ('processing', ',', 'and', 'financial', 'time'),\n",
       " (',', 'and', 'financial', 'time', 'series.CNNs'),\n",
       " ('and', 'financial', 'time', 'series.CNNs', 'are'),\n",
       " ('financial', 'time', 'series.CNNs', 'are', 'regularized'),\n",
       " ('time', 'series.CNNs', 'are', 'regularized', 'versions'),\n",
       " ('series.CNNs', 'are', 'regularized', 'versions', 'of'),\n",
       " ('are', 'regularized', 'versions', 'of', 'multilayer'),\n",
       " ('regularized', 'versions', 'of', 'multilayer', 'perceptrons'),\n",
       " ('versions', 'of', 'multilayer', 'perceptrons', '.'),\n",
       " ('of', 'multilayer', 'perceptrons', '.', 'Multilayer'),\n",
       " ('multilayer', 'perceptrons', '.', 'Multilayer', 'perceptrons'),\n",
       " ('perceptrons', '.', 'Multilayer', 'perceptrons', 'usually'),\n",
       " ('.', 'Multilayer', 'perceptrons', 'usually', 'mean'),\n",
       " ('Multilayer', 'perceptrons', 'usually', 'mean', 'fully'),\n",
       " ('perceptrons', 'usually', 'mean', 'fully', 'connected'),\n",
       " ('usually', 'mean', 'fully', 'connected', 'networks'),\n",
       " ('mean', 'fully', 'connected', 'networks', ','),\n",
       " ('fully', 'connected', 'networks', ',', 'that'),\n",
       " ('connected', 'networks', ',', 'that', 'is'),\n",
       " ('networks', ',', 'that', 'is', ','),\n",
       " (',', 'that', 'is', ',', 'each'),\n",
       " ('that', 'is', ',', 'each', 'neuron'),\n",
       " ('is', ',', 'each', 'neuron', 'in'),\n",
       " (',', 'each', 'neuron', 'in', 'one'),\n",
       " ('each', 'neuron', 'in', 'one', 'layer'),\n",
       " ('neuron', 'in', 'one', 'layer', 'is'),\n",
       " ('in', 'one', 'layer', 'is', 'connected'),\n",
       " ('one', 'layer', 'is', 'connected', 'to'),\n",
       " ('layer', 'is', 'connected', 'to', 'all'),\n",
       " ('is', 'connected', 'to', 'all', 'neurons'),\n",
       " ('connected', 'to', 'all', 'neurons', 'in'),\n",
       " ('to', 'all', 'neurons', 'in', 'the'),\n",
       " ('all', 'neurons', 'in', 'the', 'next'),\n",
       " ('neurons', 'in', 'the', 'next', 'layer'),\n",
       " ('in', 'the', 'next', 'layer', '.'),\n",
       " ('the', 'next', 'layer', '.', 'The'),\n",
       " ('next', 'layer', '.', 'The', 'fully-connectedness'),\n",
       " ('layer', '.', 'The', 'fully-connectedness', 'of'),\n",
       " ('.', 'The', 'fully-connectedness', 'of', 'these'),\n",
       " ('The', 'fully-connectedness', 'of', 'these', 'networks'),\n",
       " ('fully-connectedness', 'of', 'these', 'networks', 'makes'),\n",
       " ('of', 'these', 'networks', 'makes', 'them'),\n",
       " ('these', 'networks', 'makes', 'them', 'prone'),\n",
       " ('networks', 'makes', 'them', 'prone', 'to'),\n",
       " ('makes', 'them', 'prone', 'to', 'overfitting'),\n",
       " ('them', 'prone', 'to', 'overfitting', 'data'),\n",
       " ('prone', 'to', 'overfitting', 'data', '.'),\n",
       " ('to', 'overfitting', 'data', '.', 'Typical'),\n",
       " ('overfitting', 'data', '.', 'Typical', 'ways'),\n",
       " ('data', '.', 'Typical', 'ways', 'of'),\n",
       " ('.', 'Typical', 'ways', 'of', 'regularization'),\n",
       " ('Typical', 'ways', 'of', 'regularization', 'include'),\n",
       " ('ways', 'of', 'regularization', 'include', 'adding'),\n",
       " ('of', 'regularization', 'include', 'adding', 'some'),\n",
       " ('regularization', 'include', 'adding', 'some', 'form'),\n",
       " ('include', 'adding', 'some', 'form', 'of'),\n",
       " ('adding', 'some', 'form', 'of', 'magnitude'),\n",
       " ('some', 'form', 'of', 'magnitude', 'measurement'),\n",
       " ('form', 'of', 'magnitude', 'measurement', 'of'),\n",
       " ('of', 'magnitude', 'measurement', 'of', 'weights'),\n",
       " ('magnitude', 'measurement', 'of', 'weights', 'to'),\n",
       " ('measurement', 'of', 'weights', 'to', 'the'),\n",
       " ('of', 'weights', 'to', 'the', 'loss'),\n",
       " ('weights', 'to', 'the', 'loss', 'function'),\n",
       " ('to', 'the', 'loss', 'function', '.'),\n",
       " ('the', 'loss', 'function', '.', 'CNNs'),\n",
       " ('loss', 'function', '.', 'CNNs', 'take'),\n",
       " ('function', '.', 'CNNs', 'take', 'a'),\n",
       " ('.', 'CNNs', 'take', 'a', 'different'),\n",
       " ('CNNs', 'take', 'a', 'different', 'approach'),\n",
       " ('take', 'a', 'different', 'approach', 'towards'),\n",
       " ('a', 'different', 'approach', 'towards', 'regularization'),\n",
       " ('different', 'approach', 'towards', 'regularization', ':'),\n",
       " ('approach', 'towards', 'regularization', ':', 'they'),\n",
       " ('towards', 'regularization', ':', 'they', 'take'),\n",
       " ('regularization', ':', 'they', 'take', 'advantage'),\n",
       " (':', 'they', 'take', 'advantage', 'of'),\n",
       " ('they', 'take', 'advantage', 'of', 'the'),\n",
       " ('take', 'advantage', 'of', 'the', 'hierarchical'),\n",
       " ('advantage', 'of', 'the', 'hierarchical', 'pattern'),\n",
       " ('of', 'the', 'hierarchical', 'pattern', 'in'),\n",
       " ('the', 'hierarchical', 'pattern', 'in', 'data'),\n",
       " ('hierarchical', 'pattern', 'in', 'data', 'and'),\n",
       " ('pattern', 'in', 'data', 'and', 'assemble'),\n",
       " ('in', 'data', 'and', 'assemble', 'more'),\n",
       " ('data', 'and', 'assemble', 'more', 'complex'),\n",
       " ('and', 'assemble', 'more', 'complex', 'patterns'),\n",
       " ('assemble', 'more', 'complex', 'patterns', 'using'),\n",
       " ('more', 'complex', 'patterns', 'using', 'smaller'),\n",
       " ('complex', 'patterns', 'using', 'smaller', 'and'),\n",
       " ('patterns', 'using', 'smaller', 'and', 'simpler'),\n",
       " ('using', 'smaller', 'and', 'simpler', 'patterns'),\n",
       " ('smaller', 'and', 'simpler', 'patterns', '.'),\n",
       " ('and', 'simpler', 'patterns', '.', 'Therefore'),\n",
       " ('simpler', 'patterns', '.', 'Therefore', ','),\n",
       " ('patterns', '.', 'Therefore', ',', 'on'),\n",
       " ('.', 'Therefore', ',', 'on', 'the'),\n",
       " ('Therefore', ',', 'on', 'the', 'scale'),\n",
       " (',', 'on', 'the', 'scale', 'of'),\n",
       " ('on', 'the', 'scale', 'of', 'connectedness'),\n",
       " ('the', 'scale', 'of', 'connectedness', 'and'),\n",
       " ('scale', 'of', 'connectedness', 'and', 'complexity'),\n",
       " ('of', 'connectedness', 'and', 'complexity', ','),\n",
       " ('connectedness', 'and', 'complexity', ',', 'CNNs'),\n",
       " ('and', 'complexity', ',', 'CNNs', 'are'),\n",
       " ('complexity', ',', 'CNNs', 'are', 'on'),\n",
       " (',', 'CNNs', 'are', 'on', 'the'),\n",
       " ('CNNs', 'are', 'on', 'the', 'lower'),\n",
       " ('are', 'on', 'the', 'lower', 'extreme'),\n",
       " ('on', 'the', 'lower', 'extreme', '.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making ngrams\n",
    "cnn_ngrams=list(nltk.ngrams(cnn_tokens,5))\n",
    "cnn_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing stemming\n",
    "##### normalising words into its base form or root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In deep learn , a convolut neural network ( cnn , or convnet ) is a class of deep neural network , most commonli appli to analyz visual imageri . they are also known as shift invari or space invari artifici neural network ( siann ) , base on their shared-weight architectur and translat invari characteristics.they have applic in imag and video recognit , recommend system , imag classif , medic imag analysi , natur languag process , and financi time series.cnn are regular version of multilay perceptron . multilay perceptron usual mean fulli connect network , that is , each neuron in one layer is connect to all neuron in the next layer . the fully-connected of these network make them prone to overfit data . typic way of regular includ ad some form of magnitud measur of weight to the loss function . cnn take a differ approach toward regular : they take advantag of the hierarch pattern in data and assembl more complex pattern use smaller and simpler pattern . therefor , on the scale of connected and complex , cnn are on the lower extrem .\n"
     ]
    }
   ],
   "source": [
    "#in this step, algorithm tries to remove common prefixes and sufixes\n",
    "#this can be successful in some cases but not always\n",
    "\n",
    "#porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()\n",
    "port_stemwords=[pst.stem(word) for word in cnn_tokens]\n",
    "print(' '.join(port_stemwords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in deep learn , a convolut neural network ( cnn , or convnet ) is a class of deep neural network , most common appli to analyz visual imageri . they are also known as shift invari or space invari artifici neural network ( siann ) , base on their shared-weight architectur and translat invari characteristics.they have applic in imag and video recognit , recommend system , imag classif , medic imag analysi , natur languag process , and financi time series.cnn are regular version of multilay perceptron . multilay perceptron usual mean fulli connect network , that is , each neuron in one layer is connect to all neuron in the next layer . the fully-connected of these network make them prone to overfit data . typic way of regular includ ad some form of magnitud measur of weight to the loss function . cnns take a differ approach toward regular : they take advantag of the hierarch pattern in data and assembl more complex pattern use smaller and simpler pattern . therefor , on the scale of connected and complex , cnns are on the lower extrem .\n"
     ]
    }
   ],
   "source": [
    "#snowball stemmer\n",
    "#slightly more strict than porter stemmer, also more precise\n",
    "from nltk.stem import SnowballStemmer\n",
    "sbst=SnowballStemmer('english')  #with snowball stemmer we always need to specify the language with which we are working\n",
    "snow_stemwords=[sbst.stem(word) for word in cnn_tokens]\n",
    "print(' '.join(snow_stemwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in deep learn , a convolv neur network ( cnn , or convnet ) is a class of deep neur network , most common apply to analys vis imagery . they ar also known as shift inv or spac inv art neur network ( sian ) , bas on their shared-weights architect and transl inv characteristics.they hav apply in im and video recognit , recommend system , im class , med im analys , nat langu process , and fin tim series.cnn ar regul vert of multilay perceptron . multilay perceptron us mean ful connect network , that is , each neuron in on lay is connect to al neuron in the next lay . the fully-connectedness of thes network mak them pron to overfit dat . typ way of regul includ ad som form of magnitud meas of weight to the loss funct . cnns tak a diff approach toward regul : they tak adv of the hierarch pattern in dat and assembl mor complex pattern us smal and simpl pattern . theref , on the scal of connect and complex , cnns ar on the low extrem .\n"
     ]
    }
   ],
   "source": [
    "#Lancaster stemmer\n",
    "#very aggressive algorithm, hugely trim down your working dataset\n",
    "from nltk.stem import LancasterStemmer\n",
    "lanst=LancasterStemmer()\n",
    "lancaster_stemwords=[lanst.stem(word) for word in cnn_tokens]\n",
    "print(' '.join(lancaster_stemwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing lemmatization\n",
    "#### Lammetization is slightly different from stemming in the way that in the output of lammatization is a proper word. in stamming we can see that we obtained words like convolv, neur, etc ,  which certainly does not mean anything. Whereas in lammatization, we are going to obtain the proper words, which really stand for some meaning. Eg: gone, going,went will get converted into 'go'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:giving\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "for words in ['give','giving','given','gave']:\n",
    "    print(words+':'+word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the above words remained as it is as we did not assigned any POS tags here hence it has assumed all the wods as noun\n",
    "#### so here we need to specify the pos tags here (Parts of Speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'am', 'an', 'such', 'which', 'here', 'didn', \"should've\", 'hers', '%', 'did', 'his', 'there', '-', 've', 'with', \"wouldn't\", 'so', 'through', 'couldn', 'the', 'does', 'him', \"that'll\", '@', '[', ')', 'only', \"shan't\", 'ain', 'and', '\\\\', \"mightn't\", 'he', 'them', 'then', 'from', 'itself', 'to', 'up', 'more', 'but', '\"', \"hadn't\", 'wasn', 'm', '&', 'have', '=', 'on', 'same', \"you'll\", 'who', 'is', 'theirs', '(', ',', 'nor', \"didn't\", 'very', 'our', 'being', 'do', 'both', 'or', '!', 'most', 'those', 'before', '*', 'i', '#', 'will', 'me', \"she's\", 're', ':', '|', 'doesn', \"don't\", \"shouldn't\", 'their', 'off', \"you're\", 'now', 'once', \"wasn't\", 'been', 'my', 'ourselves', 'she', \"isn't\", 'during', 'myself', \"haven't\", 'don', 'haven', \"won't\", 'won', 'if', '$', 'while', \"it's\", 'can', 'as', 'again', \"you'd\", 'above', 'hasn', 'yourself', 'not', 'o', 'these', 'against', '<', 'having', 'what', '}', 'of', 'own', '~', 'for', 'weren', 'herself', 'yours', 'until', 'you', 'should', '{', 'mightn', 'just', 'other', 's', 'shouldn', 'isn', 'under', 'about', 'that', 'after', 'y', '.', 'this', 'its', 'were', 'in', 'some', 'needn', 'hadn', '`', 'because', 'was', 'no', 'each', 'ma', 'too', 'down', 'ours', 'whom', 'they', \"doesn't\", 'between', '?', 'any', 'her', 'has', 'when', \"'\", \"weren't\", 'shan', 'mustn', '+', '_', 'than', 'all', 'yourselves', 'below', 'd', \"couldn't\", 'wouldn', 'himself', 'doing', 'a', 't', '/', '>', 'themselves', ';', 'be', 'we', 'are', 'your', 'by', ']', 'at', 'how', 'into', 'where', \"aren't\", \"hasn't\", 'few', \"mustn't\", 'it', 'aren', 'out', 'll', 'had', '^', \"needn't\", \"you've\", 'over', 'further', 'why'}\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english')+list(punctuation))\n",
    "print(stop_words)\n",
    "print(len(stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now removing the stop wowrds from the top10 list (fdist_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# punctuation=re.compile(r'[-.?!,:;()|0-9]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'convolutional',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'CNN',\n",
       " 'ConvNet',\n",
       " 'class',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'commonly',\n",
       " 'applied',\n",
       " 'analyzing',\n",
       " 'visual',\n",
       " 'imagery',\n",
       " 'They',\n",
       " 'also',\n",
       " 'known',\n",
       " 'shift',\n",
       " 'invariant',\n",
       " 'space',\n",
       " 'invariant',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'SIANN',\n",
       " 'based',\n",
       " 'shared-weights',\n",
       " 'architecture',\n",
       " 'translation',\n",
       " 'invariance',\n",
       " 'characteristics.They',\n",
       " 'applications',\n",
       " 'image',\n",
       " 'video',\n",
       " 'recognition',\n",
       " 'recommender',\n",
       " 'systems',\n",
       " 'image',\n",
       " 'classification',\n",
       " 'medical',\n",
       " 'image',\n",
       " 'analysis',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'financial',\n",
       " 'time',\n",
       " 'series.CNNs',\n",
       " 'regularized',\n",
       " 'versions',\n",
       " 'multilayer',\n",
       " 'perceptrons',\n",
       " 'Multilayer',\n",
       " 'perceptrons',\n",
       " 'usually',\n",
       " 'mean',\n",
       " 'fully',\n",
       " 'connected',\n",
       " 'networks',\n",
       " 'neuron',\n",
       " 'one',\n",
       " 'layer',\n",
       " 'connected',\n",
       " 'neurons',\n",
       " 'next',\n",
       " 'layer',\n",
       " 'The',\n",
       " 'fully-connectedness',\n",
       " 'networks',\n",
       " 'makes',\n",
       " 'prone',\n",
       " 'overfitting',\n",
       " 'data',\n",
       " 'Typical',\n",
       " 'ways',\n",
       " 'regularization',\n",
       " 'include',\n",
       " 'adding',\n",
       " 'form',\n",
       " 'magnitude',\n",
       " 'measurement',\n",
       " 'weights',\n",
       " 'loss',\n",
       " 'function',\n",
       " 'CNNs',\n",
       " 'take',\n",
       " 'different',\n",
       " 'approach',\n",
       " 'towards',\n",
       " 'regularization',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'hierarchical',\n",
       " 'pattern',\n",
       " 'data',\n",
       " 'assemble',\n",
       " 'complex',\n",
       " 'patterns',\n",
       " 'using',\n",
       " 'smaller',\n",
       " 'simpler',\n",
       " 'patterns',\n",
       " 'Therefore',\n",
       " 'scale',\n",
       " 'connectedness',\n",
       " 'complexity',\n",
       " 'CNNs',\n",
       " 'lower',\n",
       " 'extreme']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation=[]\n",
    "for words in cnn_tokens:\n",
    "    if words not in stop_words:\n",
    "        post_punctuation.append(words)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN')]\n",
      "[('deep', 'NN')]\n",
      "[('learning', 'VBG')]\n",
      "[('convolutional', 'NN')]\n",
      "[('neural', 'JJ')]\n",
      "[('network', 'NN')]\n",
      "[('CNN', 'NN')]\n",
      "[('ConvNet', 'NN')]\n",
      "[('class', 'NN')]\n",
      "[('deep', 'NN')]\n",
      "[('neural', 'JJ')]\n",
      "[('networks', 'NNS')]\n",
      "[('commonly', 'RB')]\n",
      "[('applied', 'VBN')]\n",
      "[('analyzing', 'VBG')]\n",
      "[('visual', 'JJ')]\n",
      "[('imagery', 'NN')]\n",
      "[('They', 'PRP')]\n",
      "[('also', 'RB')]\n",
      "[('known', 'VBN')]\n",
      "[('shift', 'NN')]\n",
      "[('invariant', 'NN')]\n",
      "[('space', 'NN')]\n",
      "[('invariant', 'NN')]\n",
      "[('artificial', 'JJ')]\n",
      "[('neural', 'JJ')]\n",
      "[('networks', 'NNS')]\n",
      "[('SIANN', 'NN')]\n",
      "[('based', 'VBN')]\n",
      "[('shared-weights', 'NNS')]\n",
      "[('architecture', 'NN')]\n",
      "[('translation', 'NN')]\n",
      "[('invariance', 'NN')]\n",
      "[('characteristics.They', 'NN')]\n",
      "[('applications', 'NNS')]\n",
      "[('image', 'NN')]\n",
      "[('video', 'NN')]\n",
      "[('recognition', 'NN')]\n",
      "[('recommender', 'NN')]\n",
      "[('systems', 'NNS')]\n",
      "[('image', 'NN')]\n",
      "[('classification', 'NN')]\n",
      "[('medical', 'JJ')]\n",
      "[('image', 'NN')]\n",
      "[('analysis', 'NN')]\n",
      "[('natural', 'JJ')]\n",
      "[('language', 'NN')]\n",
      "[('processing', 'NN')]\n",
      "[('financial', 'JJ')]\n",
      "[('time', 'NN')]\n",
      "[('series.CNNs', 'NN')]\n",
      "[('regularized', 'VBN')]\n",
      "[('versions', 'NNS')]\n",
      "[('multilayer', 'NN')]\n",
      "[('perceptrons', 'NNS')]\n",
      "[('Multilayer', 'NN')]\n",
      "[('perceptrons', 'NNS')]\n",
      "[('usually', 'RB')]\n",
      "[('mean', 'NN')]\n",
      "[('fully', 'RB')]\n",
      "[('connected', 'VBN')]\n",
      "[('networks', 'NNS')]\n",
      "[('neuron', 'NN')]\n",
      "[('one', 'CD')]\n",
      "[('layer', 'NN')]\n",
      "[('connected', 'VBN')]\n",
      "[('neurons', 'NNS')]\n",
      "[('next', 'JJ')]\n",
      "[('layer', 'NN')]\n",
      "[('The', 'DT')]\n",
      "[('fully-connectedness', 'NN')]\n",
      "[('networks', 'NNS')]\n",
      "[('makes', 'VBZ')]\n",
      "[('prone', 'NN')]\n",
      "[('overfitting', 'VBG')]\n",
      "[('data', 'NNS')]\n",
      "[('Typical', 'JJ')]\n",
      "[('ways', 'NNS')]\n",
      "[('regularization', 'NN')]\n",
      "[('include', 'NN')]\n",
      "[('adding', 'VBG')]\n",
      "[('form', 'NN')]\n",
      "[('magnitude', 'NN')]\n",
      "[('measurement', 'NN')]\n",
      "[('weights', 'NNS')]\n",
      "[('loss', 'NN')]\n",
      "[('function', 'NN')]\n",
      "[('CNNs', 'NN')]\n",
      "[('take', 'VB')]\n",
      "[('different', 'JJ')]\n",
      "[('approach', 'NN')]\n",
      "[('towards', 'NNS')]\n",
      "[('regularization', 'NN')]\n",
      "[('take', 'VB')]\n",
      "[('advantage', 'NN')]\n",
      "[('hierarchical', 'JJ')]\n",
      "[('pattern', 'NN')]\n",
      "[('data', 'NNS')]\n",
      "[('assemble', 'JJ')]\n",
      "[('complex', 'JJ')]\n",
      "[('patterns', 'NNS')]\n",
      "[('using', 'VBG')]\n",
      "[('smaller', 'JJR')]\n",
      "[('simpler', 'NN')]\n",
      "[('patterns', 'NNS')]\n",
      "[('Therefore', 'RB')]\n",
      "[('scale', 'NN')]\n",
      "[('connectedness', 'NN')]\n",
      "[('complexity', 'NN')]\n",
      "[('CNNs', 'NN')]\n",
      "[('lower', 'JJR')]\n",
      "[('extreme', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#for identifying the parts of speech in the given text\n",
    "for token in post_punctuation:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nouns are detected\n",
    "#nouns are classified into names, organisations, etc\n",
    "nltk.download('maxent_ne_chunker')\n",
    "from nltk import ne_chunk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  In/IN\n",
      "  deep/JJ\n",
      "  learning/JJ\n",
      "  convolutional/JJ\n",
      "  neural/JJ\n",
      "  network/NN\n",
      "  (ORGANIZATION CNN/NNP)\n",
      "  ConvNet/NNP\n",
      "  class/NN\n",
      "  deep/JJ\n",
      "  neural/JJ\n",
      "  networks/NNS\n",
      "  commonly/RB\n",
      "  applied/VBD\n",
      "  analyzing/VBG\n",
      "  visual/JJ\n",
      "  imagery/NN\n",
      "  They/PRP\n",
      "  also/RB\n",
      "  known/VBP\n",
      "  shift/NN\n",
      "  invariant/JJ\n",
      "  space/NN\n",
      "  invariant/JJ\n",
      "  artificial/JJ\n",
      "  neural/JJ\n",
      "  networks/NNS\n",
      "  (ORGANIZATION SIANN/NNP)\n",
      "  based/VBN\n",
      "  shared-weights/NNS\n",
      "  architecture/JJ\n",
      "  translation/NN\n",
      "  invariance/NN\n",
      "  characteristics.They/NN\n",
      "  applications/NNS\n",
      "  image/NN\n",
      "  video/NN\n",
      "  recognition/NN\n",
      "  recommender/NN\n",
      "  systems/NNS\n",
      "  image/NN\n",
      "  classification/NN\n",
      "  medical/JJ\n",
      "  image/NN\n",
      "  analysis/NN\n",
      "  natural/JJ\n",
      "  language/NN\n",
      "  processing/VBG\n",
      "  financial/JJ\n",
      "  time/NN\n",
      "  series.CNNs/NN\n",
      "  regularized/VBD\n",
      "  versions/NNS\n",
      "  multilayer/JJ\n",
      "  perceptrons/NNS\n",
      "  Multilayer/NNP\n",
      "  perceptrons/NNS\n",
      "  usually/RB\n",
      "  mean/VBP\n",
      "  fully/RB\n",
      "  connected/VBN\n",
      "  networks/NNS\n",
      "  neuron/VBP\n",
      "  one/CD\n",
      "  layer/NN\n",
      "  connected/VBN\n",
      "  neurons/NNS\n",
      "  next/IN\n",
      "  layer/NN\n",
      "  The/DT\n",
      "  fully-connectedness/JJ\n",
      "  networks/NNS\n",
      "  makes/VBZ\n",
      "  prone/NN\n",
      "  overfitting/VBG\n",
      "  data/NNS\n",
      "  (ORGANIZATION Typical/NNP)\n",
      "  ways/NNS\n",
      "  regularization/NN\n",
      "  include/VBP\n",
      "  adding/VBG\n",
      "  form/JJ\n",
      "  magnitude/NN\n",
      "  measurement/JJ\n",
      "  weights/NNS\n",
      "  loss/NN\n",
      "  function/NN\n",
      "  (ORGANIZATION CNNs/NNP)\n",
      "  take/VB\n",
      "  different/JJ\n",
      "  approach/NN\n",
      "  towards/NNS\n",
      "  regularization/NN\n",
      "  take/VBP\n",
      "  advantage/NN\n",
      "  hierarchical/JJ\n",
      "  pattern/NN\n",
      "  data/NNS\n",
      "  assemble/JJ\n",
      "  complex/JJ\n",
      "  patterns/NNS\n",
      "  using/VBG\n",
      "  smaller/JJR\n",
      "  simpler/NN\n",
      "  patterns/NNS\n",
      "  Therefore/NNP\n",
      "  scale/NN\n",
      "  connectedness/NN\n",
      "  complexity/NN\n",
      "  (ORGANIZATION CNNs/NNP)\n",
      "  lower/JJR\n",
      "  extreme/NN)\n"
     ]
    }
   ],
   "source": [
    "cnn_tags=nltk.pos_tag(post_punctuation)\n",
    "cnn_NER=ne_chunk(cnn_tags)\n",
    "print(cnn_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax tree is the tree representation of syntactic structure of sentences or strings\n",
    "#with this we can form sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "#### picking up indevidual pieces of information and grouping them into bigger pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    805\u001b[0m                             \u001b[0menv_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m                         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    696\u001b[0m         find_binary_iter(\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    680\u001b[0m     for file in find_file_iter(\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m     ):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m                                         \"https://docs.brew.sh/Installation then `brew install ghostscript`\")                \n\u001b[0;32m    818\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('In', 'IN'), Tree('NP', [('deep', 'JJ'), ('learning', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN')]), Tree('ORGANIZATION', [('CNN', 'NNP')]), ('ConvNet', 'NNP'), Tree('NP', [('class', 'NN')]), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('commonly', 'RB'), ('applied', 'VBD'), ('analyzing', 'VBG'), Tree('NP', [('visual', 'JJ'), ('imagery', 'NN')]), ('They', 'PRP'), ('also', 'RB'), ('known', 'VBP'), Tree('NP', [('shift', 'NN')]), Tree('NP', [('invariant', 'JJ'), ('space', 'NN')]), ('invariant', 'JJ'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), Tree('ORGANIZATION', [('SIANN', 'NNP')]), ('based', 'VBN'), ('shared-weights', 'NNS'), Tree('NP', [('architecture', 'JJ'), ('translation', 'NN')]), Tree('NP', [('invariance', 'NN')]), Tree('NP', [('characteristics.They', 'NN')]), ('applications', 'NNS'), Tree('NP', [('image', 'NN')]), Tree('NP', [('video', 'NN')]), Tree('NP', [('recognition', 'NN')]), Tree('NP', [('recommender', 'NN')]), ('systems', 'NNS'), Tree('NP', [('image', 'NN')]), Tree('NP', [('classification', 'NN')]), Tree('NP', [('medical', 'JJ'), ('image', 'NN')]), Tree('NP', [('analysis', 'NN')]), Tree('NP', [('natural', 'JJ'), ('language', 'NN')]), ('processing', 'VBG'), Tree('NP', [('financial', 'JJ'), ('time', 'NN')]), Tree('NP', [('series.CNNs', 'NN')]), ('regularized', 'VBD'), ('versions', 'NNS'), ('multilayer', 'JJ'), ('perceptrons', 'NNS'), ('Multilayer', 'NNP'), ('perceptrons', 'NNS'), ('usually', 'RB'), ('mean', 'VBP'), ('fully', 'RB'), ('connected', 'VBN'), ('networks', 'NNS'), ('neuron', 'VBP'), ('one', 'CD'), Tree('NP', [('layer', 'NN')]), ('connected', 'VBN'), ('neurons', 'NNS'), ('next', 'IN'), Tree('NP', [('layer', 'NN')]), ('The', 'DT'), ('fully-connectedness', 'JJ'), ('networks', 'NNS'), ('makes', 'VBZ'), Tree('NP', [('prone', 'NN')]), ('overfitting', 'VBG'), ('data', 'NNS'), Tree('ORGANIZATION', [('Typical', 'NNP')]), ('ways', 'NNS'), Tree('NP', [('regularization', 'NN')]), ('include', 'VBP'), ('adding', 'VBG'), Tree('NP', [('form', 'JJ'), ('magnitude', 'NN')]), ('measurement', 'JJ'), ('weights', 'NNS'), Tree('NP', [('loss', 'NN')]), Tree('NP', [('function', 'NN')]), Tree('ORGANIZATION', [('CNNs', 'NNP')]), ('take', 'VB'), Tree('NP', [('different', 'JJ'), ('approach', 'NN')]), ('towards', 'NNS'), Tree('NP', [('regularization', 'NN')]), ('take', 'VBP'), Tree('NP', [('advantage', 'NN')]), Tree('NP', [('hierarchical', 'JJ'), ('pattern', 'NN')]), ('data', 'NNS'), ('assemble', 'JJ'), ('complex', 'JJ'), ('patterns', 'NNS'), ('using', 'VBG'), ('smaller', 'JJR'), Tree('NP', [('simpler', 'NN')]), ('patterns', 'NNS'), ('Therefore', 'NNP'), Tree('NP', [('scale', 'NN')]), Tree('NP', [('connectedness', 'NN')]), Tree('NP', [('complexity', 'NN')]), Tree('ORGANIZATION', [('CNNs', 'NNP')]), ('lower', 'JJR'), Tree('NP', [('extreme', 'NN')])])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for here chunking refers to grouping of tokens\n",
    "grammar_np=r\"NP:{<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser=nltk.RegexpParser(grammar_np)\n",
    "chunk_result=chunk_parser.parse(cnn_NER)\n",
    "chunk_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
